# Project Fern - Session Status

**Last Updated:** 2025-12-04
**Status:** In Progress - Two-Phase Navigation Implementation

---

## Current State

### âœ… Completed Features

1. **ESG Taxonomy Integration**
   - Hierarchical structure: 3 Pillars â†’ 25 Issues â†’ 642 Sub-Issues â†’ 819 Fields
   - Dynamic category loading from `esg_taxonomy.json`
   - ESG field matching with keyword-based scoring (threshold: 3.0)

2. **LLM-Driven Conversation**
   - Google Gemini integration for natural conversation
   - Structured output parsing (INTEREST_LEVEL, SUGGESTED_ACTION, RESPONSE)
   - Loop prevention (5-turn failsafe)
   - Explicit move-on signal detection

3. **Debug Features**
   - Console logging toggle
   - Debug panel in sidebar showing:
     - Turn count
     - Commitment detection
     - Loop prevention status
     - Matched ESG Field IDs with scores
   - Expandable/collapsible debug panel

4. **Response Quality Improvements**
   - Concise response guidelines (1-2 sentences max)
   - Values-based questioning (not taxonomy terms)
   - Removed filler phrases ("I understand", "When you think about it")
   - Examples of good vs. bad responses in prompts

5. **Two-Phase Navigation Structure** (Partially Implemented)
   - Phase 1: Pillar intro categories added (Environmental, Social, Governance)
   - Phase 2: Issue categories added (25 total)
   - LLM extracts mentioned Issues during Pillar intro
   - `mentioned_issues` tracking in session state

---

## âš ï¸ Known Issues

### Issue #1: Redundant Issue Drill-Down

**Problem:**
Bot explores an Issue during Pillar intro (e.g., climate change with 3+ turns of discussion), then asks about it again with "You mentioned Climate Exposure as a concern. Can you tell me more?"

**Example:**
```
Bot: What environmental issues come to mind?
User: Climate change
Bot: What aspects matter most?
User: Global trends
Bot: Economy or ecosystems?
User: Broader economy
Bot: [should ask about OTHER environmental topics]
     [instead asks] You mentioned Climate Exposure. Tell me more? âŒ
```

**Root Cause:**
No tracking of which Issues were "explored" (2+ turns of discussion) vs. just "mentioned" during Pillar intro.

**Expected Behavior:**
- If Issue was explored in Pillar intro (2+ turns): Skip Issue-specific drill-down
- If Issue was mentioned but not explored: Ask Issue-specific question
- After exploring Issues, ask: "Are there other environmental topics you care about?"

---

### Issue #2: Premature Pillar Transition

**Problem:**
After discussing one Issue in depth, bot sometimes skips to next Pillar without asking about other Issues in current Pillar.

**Expected Behavior:**
Stay in Pillar intro, ask: "Are there other environmental issues you care about?" before moving to Social.

---

## ðŸ”„ In Progress

### Two-Phase Navigation - Smart Issue Tracking

**Goal:**
Distinguish between Issues that were:
1. **Explored** (2+ turns of discussion during Pillar intro) â†’ Skip drill-down
2. **Mentioned** (said once, not elaborated) â†’ Drill down later
3. **Not mentioned** (never came up) â†’ Skip entirely

**Implementation Plan:**
1. Add `explored_issues` set to session state (tracks Issues with 2+ turns)
2. During Pillar intro, if turn_count >= 2 on an Issue, mark as explored
3. In `_navigate_to_next_relevant_category()`:
   - Skip Issues in `explored_issues`
   - Only drill into Issues in `mentioned_issues` but not `explored_issues`
4. After finishing Issue drill-downs, before moving to next Pillar, ask:
   - "Are there other [environmental/social/governance] topics you care about?"

**Files to Modify:**
- `app.py`: Add `explored_issues` tracking, update navigation logic
- `src/prompts.py`: Possibly update MENTIONED_ISSUES extraction to include exploration depth

---

## ðŸ“‹ Next Session Tasks

### Priority 1: Fix Redundant Drill-Down
**Estimated Time:** 30-40 minutes

1. Add `explored_issues` set to session state in `initialize_session_state()`
2. Track exploration depth in `process_category_response()`:
   - If `category_type == 'pillar_intro'` and `turn_count >= 2` on an Issue, add to `explored_issues`
3. Update `_navigate_to_next_relevant_category()`:
   - Skip Issues in `explored_issues`
   - Only navigate to Issues in `mentioned_issues` but not in `explored_issues`
4. Add prompt to ask about other topics before moving to next Pillar

### Priority 2: Test Complete Flow
**Estimated Time:** 30 minutes

Test scenarios:
1. **Explore one Issue deeply** (3+ turns) â†’ Should skip drill-down, ask about other topics
2. **Mention multiple Issues briefly** â†’ Should drill into each mentioned Issue
3. **Mix of explored + mentioned** â†’ Should only drill into non-explored Issues
4. **No interest in Pillar** â†’ Should skip to next Pillar

### Priority 3: Documentation Updates
**Estimated Time:** 15 minutes

Update docs to reflect new navigation flow:
- `HIERARCHY_REFACTOR.md`: Update example conversation
- `TESTING_GUIDE.md`: Add test cases for two-phase navigation

---

## ðŸ—‚ï¸ File Structure

### Core Application Files
- `app.py` - Main Streamlit application, navigation logic
- `src/conversation.py` - Conversation state, ESG field matching, turn counting
- `src/prompts.py` - LLM prompts, response guidelines
- `src/taxonomy_hierarchy.py` - Builds category structure from taxonomy
- `src/llm.py` - Google Gemini integration

### Data Files
- `data/processed/esg_taxonomy.json` - 819 ESG fields, hierarchical structure
- `data/raw/*.csv` - Original datasets

### Documentation
- `SESSION_STATUS.md` - This file (current state + next steps)
- `REFACTOR_SUMMARY.md` - Summary of taxonomy-based hierarchy refactor
- `HIERARCHY_REFACTOR.md` - Detailed technical docs for hierarchy system
- `INTEGRATION_COMPLETE.md` - ESG field matching integration docs
- `LOOP_FIX_SUMMARY.md` - Loop prevention and commitment detection docs
- `TESTING_GUIDE.md` - Testing scenarios and expected behavior

---

## ðŸŽ¯ Design Decisions

### Navigation Philosophy
- **User-driven depth**: Let users determine how deep to explore each topic
- **No forced paths**: Skip topics user doesn't mention
- **Natural flow**: Conversation should feel like talking to an advisor, not filling out a form

### LLM Prompt Strategy
- **Structured output**: Force LLM to output parseable fields (INTEREST_LEVEL, SUGGESTED_ACTION, RESPONSE)
- **Values-based questions**: Ask "why" not "what" - help users think about philosophy
- **Concise style**: 1-2 sentences max, cut filler phrases
- **No premature closure**: Never ask "ready to move on?" - let user signal

### State Management
- `mentioned_issues`: Issues user brought up during Pillar intro
- `explored_issues`: Issues discussed for 2+ turns (to be implemented)
- `category_turn_count`: Turns spent on current category (reset on navigation)
- `debug_mode`: Toggle for console logging

---

## ðŸ”§ Configuration

### LLM Settings
- **Model**: Google Gemini (via `src/llm.py`)
- **System Prompt**: Defined in `src/prompts.py` (SYSTEM_PROMPT)
- **Temperature**: Default (not explicitly set)

### ESG Field Matching
- **Matching Threshold**: 3.0 (keyword-based scoring)
- **Fields Displayed**: Top 3 matches
- **Keywords Per Field**: Varies (defined in taxonomy data)

### Loop Prevention
- **Max Turns**: 5 turns per category before auto-advance
- **Explicit Move-On Phrases**: "let's move on", "next topic", "that's all", "that's it", "done with this"

---

## ðŸ’¡ Future Enhancements (Backlog)

### Short Term
1. **Improve ESG Field Matching**
   - Upgrade from keyword-based to embedding-based (semantic matching)
   - Show confidence scores to user
   - Allow user to confirm/reject matches

2. **Better Progress Indicator**
   - Show which Pillar user is in
   - Indicate explored vs. remaining topics

3. **Conversation Summary**
   - Mid-conversation recap: "So far you've mentioned..."
   - Help user remember what they've already covered

### Long Term
1. **Export Formats**
   - JSON export with Field IDs for integration with other tools
   - PDF report with charts/visualizations

2. **Multi-Language Support**
   - Translate prompts and UI
   - Maintain taxonomy in multiple languages

3. **Personalization**
   - Remember user from previous sessions
   - Adapt questioning style based on user expertise level

---

## ðŸ“ž Handoff Notes

### For Next Session

**Where We Left Off:**
- Discussed the redundancy issue where bot re-asks about explored Issues
- Agreed on solution: track `explored_issues` (2+ turns) vs. `mentioned_issues` (1 turn)
- Ready to implement the fix

**Quick Start:**
1. Open `app.py`
2. Add `explored_issues` set to session state (line ~90)
3. Update `process_category_response()` to track when turn_count >= 2 on an Issue
4. Modify `_navigate_to_next_relevant_category()` to skip explored Issues

**Test Command:**
```bash
streamlit run app.py
```

**Expected Test Flow:**
```
Bot: What environmental issues come to mind?
User: Climate change
Bot: What aspects matter most? [turn 1]
User: Global trends
Bot: Economy or ecosystems? [turn 2]
User: Broader economy [turn 3 - mark Climate Exposure as explored]
Bot: Are there other environmental topics you care about? âœ…
```

---

**Session End Time:** 2025-12-04
**Next Session:** Continue with explored_issues implementation
